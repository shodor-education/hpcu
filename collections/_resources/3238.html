---
title: "XSEDE MPI Workshop Video 4 of 6"
url: "https://youtu.be/18dTf94K-k4"
creator: "John Urbanic, Parallel Computing Scientist at Pittsburgh Supercomputing Center"
description: "In this video John Urbanic lectures on advanced MPI uses, functions, and techniques. Some of these topics include user defined data types, dynamic memory, communicators, and collectives."
relation: "https://www.psc.edu/hpc-workshop-series/mpi"
rights: "https://youtu.be/18dTf94K-k4"
language: "English"
audience:
  - "Learner/Student"
  - "Researcher"
  - "Student"
type:
  - "Instructional Material"
  - "Lecture/Presentation"
  - "Software"
  - "Tool"
  - "Tutorial"
subject:
  - "Computational Science"
  - "Computer Science"
format:
  - "HTML"
  - "Slide"
education-level:
  - "Graduate/Professional"
  - "Higher Education"
  - "Undergraduate (Upper Division)"
keyword:
  - "C"
  - "Fortran"
  - "Library"
  - "MPI"
  - "MPI-IO"
  - "MPI_Aint"
  - "PE"
  - "Passive"
  - "RMA"
  - "SMP"
  - "Scalable"
  - "active"
  - "allocate"
  - "attribute"
  - "attributes"
  - "blocking"
  - "buffer"
  - "cartesian"
  - "collective"
  - "collectives"
  - "communication"
  - "communicators"
  - "data"
  - "data type"
  - "datatypes"
  - "dynamic"
  - "fence"
  - "gather"
  - "graph"
  - "history"
  - "hybrid"
  - "management"
  - "master"
  - "memory"
  - "message"
  - "neighbor"
  - "neighborhood"
  - "non-blocking"
  - "optimized parallel IO"
  - "options"
  - "paradigm"
  - "parallel"
  - "parallel IO"
  - "parallel disk system"
  - "passing"
  - "performance"
  - "process"
  - "programming"
  - "race condition"
  - "reduce"
  - "remote"
  - "remote memory access"
  - "routine"
  - "scatter"
  - "shared"
  - "simplified lustre"
  - "single-sided"
  - "slave"
  - "static"
  - "struct"
  - "synchronization"
  - "topology"
  - "user defined"
  - "vector"
  - "window"
hpcu-subject:
  - "Code Optimization"
  - "Programming/Algorithms"
  - "Scalable Computing"
location:
  - "North America"
  - "United States"
difficulty: "Advanced"
hpcu-subject-2:
  - "Architectures, Devices, Hardware"
  - "Attributes"
  - "Best Practices"
  - "Blocked Partitioning"
  - "Code"
  - "Communication"
  - "Computational Science"
  - "Computer Program"
  - "Computer Science"
  - "Computer Systems Organization"
  - "Computing Categories"
  - "Concurrency, Concurrent"
  - "Data Distribution"
  - "Data Management"
  - "Data Parallelism"
  - "Data Transfers"
  - "Data Types"
  - "Data, Input/Output"
  - "Deadlock"
  - "Dynamic Load Balancing"
  - "Execution, Workload"
  - "Files and File Systems"
  - "Flow"
  - "Functional Parallelism"
  - "General Concepts"
  - "Hierarchy"
  - "Load Balance"
  - "Load Balancing"
  - "Methodologies"
  - "Mixed Data Types"
  - "Network Topologies"
  - "Networks"
  - "Parallel Code"
  - "Parallel Computing"
  - "Parallel Data Transfers"
  - "Parallel File System"
  - "Parallel I/O"
  - "Parallel Program"
  - "Parallel, Parallelism"
  - "Physical Science and Engineering"
  - "Problem Solving"
  - "Process"
  - "Race Condition"
  - "Resource Allocation"
  - "Resource Management"
  - "Scalability"
  - "Scale"
  - "Scaling"
  - "Scientific Computing"
  - "Serial, Sequential"
  - "Software"
  - "Static Load Balancing"
  - "Strong Scalability"
  - "Subject Areas"
  - "Synchronization"
  - "Synchronization Mechanisms"
  - "Threads"
  - "Vector"
  - "Weak Scalability"
hpcu-keywords:
  - "C"
  - "Co-Array FORTRAN"
  - "FORTRAN"
  - "MPI"
  - "MPI I/O"
---
